{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIGIT RECOGNIZER USING A CONV NET IN KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D,BatchNormalization,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the file\n",
    "train = pd.read_csv('../Digit_recognizer/data/train.csv')\n",
    "test = pd.read_csv('../Digit_recognizer/data/test.csv')\n",
    "Y_orig = np.array(train['label'][:])\n",
    "X_orig = np.array(train.drop(['label'],axis=1)[:])\n",
    "X_test = np.array(test[:]).reshape(-1,28,28,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (42000, 28, 28, 1)\n",
      "Label of the trained image: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2738af466d8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_orig_reshape = X_orig.reshape(-1,28,28,1)\n",
    "print('Shape of X_train:',X_orig_reshape.shape)\n",
    "index = 2\n",
    "plt.imshow(X_orig_reshape[index,:,:,0])\n",
    "print('Label of the trained image:',Y_orig[index])\n",
    "#plt.imshow(X_test[index,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_labels = len(np.unique(Y_orig))\n",
    "Y_orig_reshape = np.eye(uniq_labels)[Y_orig.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = train_test_split(X_orig_reshape,Y_orig_reshape,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (37800, 28, 28, 1)\n",
      "Shape of Y_train:  (37800, 10)\n",
      "Shape of X_val:  (4200, 28, 28, 1)\n",
      "Shape of Y_val:  (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train: ',X_train.shape)\n",
    "print('Shape of Y_train: ',Y_train.shape)\n",
    "print('Shape of X_val: ',X_val.shape)\n",
    "print('Shape of Y_val: ',Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Make a Input -> [CONV2D(16,3x3)] -> Maxpool -> [CONV2D(32,3x3)]^2 -> flatten -> Dense layer --> Dense layer\n",
    "#L1 - Results in 25*25*16 and then pools to 15\n",
    "model.add(Conv2D(activation='relu',kernel_size=(3,3),filters=16,input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "\n",
    "#L2\n",
    "model.add(Conv2D(activation='relu',kernel_size=(3,3),filters=32))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "#L3\n",
    "model.add(Flatten())\n",
    "#L4 - Dense\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#L5 - Dense\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#L6 - Dense output layer\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "            optimizer = Adam(lr = 0.0001), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/20\n",
      "37800/37800 [==============================] - 141s 4ms/step - loss: 0.2561 - acc: 0.9198 - val_loss: 0.0809 - val_acc: 0.9755\n",
      "Epoch 2/20\n",
      "37800/37800 [==============================] - 137s 4ms/step - loss: 0.0761 - acc: 0.9762 - val_loss: 0.0636 - val_acc: 0.9807\n",
      "Epoch 3/20\n",
      "37800/37800 [==============================] - 135s 4ms/step - loss: 0.0486 - acc: 0.9845 - val_loss: 0.0555 - val_acc: 0.9829\n",
      "Epoch 4/20\n",
      "37800/37800 [==============================] - 137s 4ms/step - loss: 0.0342 - acc: 0.9892 - val_loss: 0.0505 - val_acc: 0.9845\n",
      "Epoch 5/20\n",
      "37800/37800 [==============================] - 136s 4ms/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0487 - val_acc: 0.9843\n",
      "Epoch 6/20\n",
      "37800/37800 [==============================] - 138s 4ms/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.0531 - val_acc: 0.9840\n",
      "Epoch 7/20\n",
      "37800/37800 [==============================] - 136s 4ms/step - loss: 0.0133 - acc: 0.9955 - val_loss: 0.0484 - val_acc: 0.9860\n",
      "Epoch 8/20\n",
      "37800/37800 [==============================] - 150s 4ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0502 - val_acc: 0.9869\n",
      "Epoch 9/20\n",
      "37800/37800 [==============================] - 153s 4ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0471 - val_acc: 0.9893\n",
      "Epoch 10/20\n",
      "37800/37800 [==============================] - 156s 4ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0514 - val_acc: 0.9876\n",
      "Epoch 11/20\n",
      "37800/37800 [==============================] - 137s 4ms/step - loss: 0.0074 - acc: 0.9975 - val_loss: 0.0520 - val_acc: 0.9862\n",
      "Epoch 12/20\n",
      "37800/37800 [==============================] - 136s 4ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0522 - val_acc: 0.9879\n",
      "Epoch 13/20\n",
      "37800/37800 [==============================] - 137s 4ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0676 - val_acc: 0.9852\n",
      "Epoch 14/20\n",
      "37800/37800 [==============================] - 136s 4ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0609 - val_acc: 0.9869\n",
      "Epoch 15/20\n",
      "37800/37800 [==============================] - 136s 4ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0561 - val_acc: 0.9871\n",
      "Epoch 16/20\n",
      "37800/37800 [==============================] - 135s 4ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0562 - val_acc: 0.9879\n",
      "Epoch 17/20\n",
      "37800/37800 [==============================] - 137s 4ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0540 - val_acc: 0.9883\n",
      "Epoch 18/20\n",
      "37800/37800 [==============================] - 136s 4ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0581 - val_acc: 0.9881\n",
      "Epoch 19/20\n",
      "37800/37800 [==============================] - 137s 4ms/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0589 - val_acc: 0.9886\n",
      "Epoch 20/20\n",
      "37800/37800 [==============================] - 135s 4ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0680 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273832d6d68>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=Y_train,batch_size=64,epochs=20,verbose=1,callbacks=None,validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415   0   1   0   0   0   1   0   1   0]\n",
      " [  0 464   2   0   0   1   1   1   0   0]\n",
      " [  0   0 382   0   0   0   0   0   3   0]\n",
      " [  0   0   0 435   0   3   0   0   3   1]\n",
      " [  0   0   0   0 411   0   2   2   0   3]\n",
      " [  0   0   0   2   0 365   0   0   0   0]\n",
      " [  1   0   0   1   0   0 390   0   1   0]\n",
      " [  0   1   7   0   0   0   0 445   0   1]\n",
      " [  0   0   0   0   0   0   2   0 441   1]\n",
      " [  2   0   0   0   1   2   0   1   5 399]]\n"
     ]
    }
   ],
   "source": [
    "prob = model.predict(X_val)\n",
    "pred = np.argmax(prob,axis=1)\n",
    "actual = np.argmax(Y_val,axis=1)\n",
    "conf_mat = confusion_matrix(y_true=actual,y_pred=pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_prob = model.predict(X_test) \n",
    "submissions = np.argmax(submissions_prob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  = pd.DataFrame(submissions).reset_index()\n",
    "out.columns = ['ImageID','Label']\n",
    "out['ImageID'] += 1\n",
    "out.to_csv(\"../Digit_recognizer/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
