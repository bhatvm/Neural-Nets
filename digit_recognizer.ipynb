{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Digit Recognizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been read\n"
     ]
    }
   ],
   "source": [
    "#print(train)\n",
    "Y = train[\"label\"]\n",
    "X = train.drop([\"label\"],axis = 1)\n",
    "\n",
    "if X.shape[0] > 1:\n",
    "    print(\"Files have been read\")\n",
    "\n",
    "X_test = test\n",
    "\n",
    "nr_samples = 30000\n",
    "y_train=Y[:nr_samples]\n",
    "X_train=X[:nr_samples]\n",
    "start_ix_val = nr_samples \n",
    "end_ix_val = nr_samples + int(nr_samples/3)\n",
    "y_val=Y[start_ix_val:end_ix_val]\n",
    "X_val=X[start_ix_val:end_ix_val]\n",
    "\n",
    "m = X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X -> :\")\n",
    "print(X.info())\n",
    "\n",
    "print(\"X_test -> :\")\n",
    "print(X_test.info())\n",
    "\n",
    "print(\"Y -> :\")\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the dist of all the labels in Y\n",
    "Y.value_counts().plot(kind = \"bar\") # Looks equally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check images for the first for each label\n",
    "li_idx = []\n",
    "for i in range(5):\n",
    "    for nr in range(10):\n",
    "        ix = Y[Y==nr].index[i]\n",
    "        li_idx.append(ix)\n",
    "print(li_idx)\n",
    "\n",
    "#plot the images\n",
    "fig,axis = plt.subplots(5,10,sharex=True,sharey=True,figsize = (10,6))\n",
    "axis = axis.flatten()\n",
    "for n,i in enumerate(li_idx):\n",
    "    #print(n,i)\n",
    "    im = X.iloc[i]\n",
    "    #print(im)\n",
    "    im = im.values.reshape(-1,28,28,1)\n",
    "    #print(im)\n",
    "    axis[n].imshow(im[0,:,:,0])\n",
    "    axis[n].set_title(Y[i])\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.014, 0.012], 'penalty': ['l1'], 'multi_class': ['multinomial'], 'solver': ['saga'], 'tol': [0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression()\n",
    "param_grid = {'C':[0.014,0.012],'multi_class':['multinomial'],'penalty':['l1'],'solver':['saga'],'tol':[0.1]}\n",
    "gridCV_LR = GridSearchCV(clf_LR,param_grid=param_grid,verbose=1,cv = 5)\n",
    "gridCV_LR.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165333333333333\n"
     ]
    }
   ],
   "source": [
    "print(gridCV_LR.best_score_) \n",
    "#print(gridCV_LR.best_params_)\n",
    "#gridCV_LR.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [50], 'max_features': [100], 'min_samples_split': [5], 'max_depth': [15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_RF = RandomForestClassifier()\n",
    "param_grid_RF = {'max_depth':[15],'max_features':[100],'min_samples_split':[5],'n_estimators':[50]}\n",
    "gridCV_RF = GridSearchCV(clf_RF,param_grid=param_grid_RF,verbose=1,cv = 5)\n",
    "gridCV_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525666666666667\n"
     ]
    }
   ],
   "source": [
    "print(gridCV_RF.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 16.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'max_features': [100], 'min_samples_split': [5], 'n_estimators': [50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GB = GradientBoostingClassifier()\n",
    "param_grid_GB = {'learning_rate':[0.01,0.05,0.1],'n_estimators': [50], 'max_features': [100], 'min_samples_split': [5]}\n",
    "gridCV_GB = GridSearchCV(clf_GB,param_grid=param_grid_GB,cv=5,verbose=1)\n",
    "gridCV_GB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_features': 100,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridCV_GB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression: 91.84%\n",
      " Random Forest : 91.84%\n",
      " Gradient Boosting: 92.46%\n"
     ]
    }
   ],
   "source": [
    "y_pred_LR = gridCV_LR.predict(X_val)\n",
    "y_pred_GB = gridCV_GB.predict(X_val)\n",
    "y_pred_RF = gridCV_LR.predict(X_val)\n",
    "\n",
    "accuracy_LR = accuracy_score(y_pred=y_pred_LR,y_true=y_val)*100\n",
    "accuracy_RF = accuracy_score(y_pred=y_pred_RF,y_true=y_val)*100\n",
    "accuracy_GB = accuracy_score(y_pred=y_pred_GB,y_true=y_val)*100\n",
    "\n",
    "print(\" Logistic Regression: %1.2f\" %accuracy_LR + '%')\n",
    "print(\" Random Forest : %1.2f\" %accuracy_RF + '%')\n",
    "print(\" Gradient Boosting: %1.2f\" %accuracy_GB + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 953,    0,    4,    2,    2,   11,    9,    3,    6,    5],\n",
       "       [   0, 1104,    6,    5,    7,    6,    2,    3,   28,    8],\n",
       "       [   6,    3,  875,   33,    4,    8,   10,   16,    7,    7],\n",
       "       [   3,    3,   15,  956,    1,   29,    1,    7,   24,   14],\n",
       "       [   1,    2,    9,    0,  850,   13,    9,    7,    2,   28],\n",
       "       [  12,    1,    4,   25,    1,  778,   11,    0,   28,    8],\n",
       "       [  14,    0,   14,    2,   12,   19,  904,    1,    2,    1],\n",
       "       [   3,    2,   11,   13,    1,    3,    0,  979,    3,   32],\n",
       "       [   6,   12,   25,   14,    7,   36,    5,    1,  885,    5],\n",
       "       [   0,    0,    4,   10,   29,   11,    0,   49,   10,  900]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fig,axis = plt.subplots(1,3,sharex=True,sharey=True)\n",
    "print(\"Logistic regression: Confusion Matrix\")\n",
    "confusion_matrix(y_pred_LR,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost: Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 964,    0,    8,    3,    3,   11,   11,    7,    3,    3],\n",
       "       [   0, 1109,    3,    9,    4,   10,    3,    6,   24,    8],\n",
       "       [   2,    4,  886,   36,    2,    1,    3,   12,    6,    4],\n",
       "       [   3,    5,   14,  935,    1,   35,    0,    4,   15,   10],\n",
       "       [   2,    0,   11,    0,  856,    6,   13,    9,    4,   32],\n",
       "       [   5,    4,    5,   22,    3,  813,   19,    3,   17,    8],\n",
       "       [   6,    2,   10,    4,    2,   14,  890,    0,    1,    0],\n",
       "       [   1,    0,    9,   12,    1,    1,    1,  987,    3,   29],\n",
       "       [  15,    3,   19,   25,    7,   11,   11,    4,  900,    8],\n",
       "       [   0,    0,    2,   14,   35,   12,    0,   34,   22,  906]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Gradient Boost: Confusion Matrix\")\n",
    "confusion_matrix(y_pred_GB,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 953,    0,    4,    2,    2,   11,    9,    3,    6,    5],\n",
       "       [   0, 1104,    6,    5,    7,    6,    2,    3,   28,    8],\n",
       "       [   6,    3,  875,   33,    4,    8,   10,   16,    7,    7],\n",
       "       [   3,    3,   15,  956,    1,   29,    1,    7,   24,   14],\n",
       "       [   1,    2,    9,    0,  850,   13,    9,    7,    2,   28],\n",
       "       [  12,    1,    4,   25,    1,  778,   11,    0,   28,    8],\n",
       "       [  14,    0,   14,    2,   12,   19,  904,    1,    2,    1],\n",
       "       [   3,    2,   11,   13,    1,    3,    0,  979,    3,   32],\n",
       "       [   6,   12,   25,   14,    7,   36,    5,    1,  885,    5],\n",
       "       [   0,    0,    4,   10,   29,   11,    0,   49,   10,  900]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random Forest: Confusion Matrix\")\n",
    "confusion_matrix(y_pred_RF,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY NEURAL NETWORK AND SEE IF THIS IMPROVES ACCURACY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 51.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate_init': [0.01, 0.001], 'learning_rate': ['constant'], 'max_iter': [300], 'solver': ['sgd'], 'batch_size': [32]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(activation = \"logistic\",hidden_layer_sizes = (200,20))\n",
    "param_grid_NN = {'batch_size':[32], 'solver': ['sgd'], 'learning_rate':['constant'], \n",
    "                 'learning_rate_init':[0.01,0.001], 'max_iter':[300]}\n",
    "gridCV_NN = GridSearchCV(clf_NN,cv=5,verbose=1,param_grid=param_grid_NN)\n",
    "gridCV_NN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECK IF NN DOES WELL ON TEST AND VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.95\n",
      "Test Accuracy: 0.95\n",
      "NN Confusion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 970,    0,    9,    1,    1,    6,   11,    2,    3,    5],\n",
       "       [   0, 1103,    1,    3,    5,    4,    3,    3,    8,    4],\n",
       "       [   2,    3,  919,   19,    1,    2,    2,    7,    3,    2],\n",
       "       [   0,    3,    3,  993,    0,   21,    0,    4,   14,   13],\n",
       "       [   1,    2,    4,    0,  857,    7,    1,    2,    2,   25],\n",
       "       [   4,    0,    1,   21,    0,  853,    7,    3,    9,    7],\n",
       "       [   9,    1,    9,    2,   10,   13,  923,    0,    3,    1],\n",
       "       [   2,    3,   11,    4,    1,    2,    0, 1027,    0,   26],\n",
       "       [   8,   12,    9,   13,    4,    3,    4,    2,  942,    5],\n",
       "       [   2,    0,    1,    4,   35,    3,    0,   16,   11,  920]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Accuracy: %1.2f\"%gridCV_NN.best_score_)\n",
    "y_pred_NN = gridCV_NN.predict(X_val)\n",
    "print(\"Test Accuracy: %1.2f\"%accuracy_score(y_pred_NN,y_val))\n",
    "print(\"NN Confusion\")\n",
    "confusion_matrix(y_pred_NN,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write NN predictions into a csv\n",
    "submission = gridCV_NN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.DataFrame(submission).reset_index()\n",
    "csv.columns=['ImageID','Label']\n",
    "csv[\"ImageID\"]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.to_csv(\"../submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write GBM predictions into a csv\n",
    "sub2 = gridCV_GB.predict(X_test)\n",
    "csv2 = pd.DataFrame(sub2).reset_index()\n",
    "csv2.columns = ['ImageID','Label']\n",
    "csv2['ImageID'] += 1\n",
    "csv2.to_csv(\"../submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
